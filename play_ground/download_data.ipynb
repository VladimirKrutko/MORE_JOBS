{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import loader as Loader\n",
    "import parser as Parser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Loader.Loader()\n",
    "base_url = 'https://it.pracuj.pl/praca'\n",
    "file_names = []\n",
    "for page_number in range(1, 93):\n",
    "    page_url = f\"{base_url}?pn={page_number}\" if page_number > 1 else base_url\n",
    "    file_names.append( loader.crawler(page_url, f'main_page_page{page_number}') )\n",
    "    # file_names.append( loader.crawler(f\"{base_url}\") if page_number == 1 else loader.crawler(f\"{base_url}?pn={page_number}\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir('temp_data')\n",
    "for file_name in file_names:\n",
    "    base_file_name = file_name.split('_')[2]\n",
    "    parser = Parser.Parser( f\"./temp_data/{file_name}\", base_file_name)\n",
    "    parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser.Parser(file_path='./temp_data/pl_1707575579327143.html', base_file_name='page_1')\n",
    "parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CustomLoader\n",
    "from LoginScript import LoginScript\n",
    "\n",
    "todos = []\n",
    "for todo_file in os.listdir('todos'):\n",
    "    with open(f\"./todos/{todo_file}\") as f:\n",
    "        [todos.append(line.strip()) for line in f]\n",
    "\n",
    "cookies = False\n",
    "loader = Loader.Loader()\n",
    "for url2todo in todos:\n",
    "    if not(cookies):\n",
    "        cookies = LoginScript().click_button_and_get_cookies(url2todo)\n",
    "        cookies = { ck['name']:ck['value'] for ck in cookies}\n",
    "        \n",
    "    result = CustomLoader.CustomLoader.crawl(url2todo,'offer_pages/offer', cookies)\n",
    "    if not(result):\n",
    "        cookies = LoginScript().click_button_and_get_cookies(url2todo)\n",
    "        cookies = { ck['name']:ck['value'] for ck in cookies}\n",
    "\n",
    "        with open('unparsable_todo.txt', 'a') as f:\n",
    "            f.write(url2todo)\n",
    "\n",
    "    # if ~result:\n",
    "    #     with open('unparsable_todo.txt'):\n",
    "    # # loader.crawler(url2todo, 'offer_pages/offer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./offer_data/html_pages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 2,
>>>>>>> e2183e3 (extract data from html to json)
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from custom_parser.PageParser import PageParser\n",
    "\n",
    "file_name = os.listdir('./offer_data/html_pages')\n",
    "for i in range(0, 4601, 500):\n",
    "    page_jsons = []\n",
    "    for file in file_name[i:i+500]:\n",
    "        page_jsons.append(PageParser(f\"./offer_data/html_pages/{file}\").parse_json())\n",
<<<<<<< HEAD
    "    with open(f'./offer_data/json_pages/{int(time.time()*1000000)}.json', 'w') as f:\n",
    "        json.dump(page_jsons, f)"
=======
    "    with open(f'./offer_data/json_pages/{time.time()}.json', 'w') as f:\n",
    "        json.dump(page_jsons, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_names = [ for f in  ]"
>>>>>>> e2183e3 (extract data from html to json)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
